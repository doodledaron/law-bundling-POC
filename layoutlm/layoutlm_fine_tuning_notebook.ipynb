{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LayoutLM Fine-Tuning for NER\n",
    "\n",
    "This notebook provides a step-by-step process for fine-tuning LayoutLM on a token classification (NER) task using the dataset prepared by merge-ocr-conll.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries\n",
    "\n",
    "Run this cell to install the required libraries if you haven't already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, Features, Sequence, ClassLabel, Value, Array2D\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     LayoutLMForTokenClassification, \n\u001b[32m      9\u001b[39m     LayoutLMTokenizerFast,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     DataCollatorForTokenClassification\n\u001b[32m     13\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mevaluate\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import Dataset, Features, Sequence, ClassLabel, Value, Array2D\n",
    "from transformers import (\n",
    "    LayoutLMForTokenClassification, \n",
    "    LayoutLMTokenizerFast,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Dataset and Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the prepared dataset\n",
    "with open('layoutlm_dataset.json', 'r', encoding='utf-8') as f:\n",
    "    dataset_json = json.load(f)\n",
    "\n",
    "# Load the label map\n",
    "with open('label_map.json', 'r', encoding='utf-8') as f:\n",
    "    label_map = json.load(f)\n",
    "\n",
    "label_to_id = label_map['label_to_id']\n",
    "id_to_label = label_map['id_to_label']\n",
    "num_labels = len(label_to_id)\n",
    "\n",
    "print(f\"Loaded dataset with {len(dataset_json)} examples\")\n",
    "print(f\"Number of labels: {num_labels}\")\n",
    "print(\"Labels:\")\n",
    "for label, id in sorted(label_to_id.items(), key=lambda x: x[1]):\n",
    "    print(f\"  {id}: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Hugging Face Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features for our dataset\n",
    "features = Features({\n",
    "    'id': Value('string'),\n",
    "    'words': Sequence(Value('string')),\n",
    "    'boxes': Sequence(Sequence(Value('int64'), length=4)),\n",
    "    'ner_tags': Sequence(ClassLabel(num_classes=num_labels, names=list(label_to_id.keys())))\n",
    "})\n",
    "\n",
    "# Create a dataset from the JSON\n",
    "dataset = Dataset.from_list(dataset_json, features=features)\n",
    "\n",
    "# Split dataset into train and eval sets (80/20 split)\n",
    "# In a real scenario, you might want to use a more sophisticated split\n",
    "# or have separate validation and test sets\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "print(f\"Train set: {len(dataset['train'])} examples\")\n",
    "print(f\"Test set: {len(dataset['test'])} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize TokenizerFast and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer and model\n",
    "tokenizer = LayoutLMTokenizerFast.from_pretrained('microsoft/layoutlm-base-uncased')\n",
    "model = LayoutLMForTokenClassification.from_pretrained(\n",
    "    'microsoft/layoutlm-base-uncased',\n",
    "    num_labels=num_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prepare the Tokenizer and Data Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize and align labels\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"words\"],\n",
    "        boxes=examples[\"boxes\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "        is_split_into_words=True,\n",
    "        return_token_type_ids=True,\n",
    "        return_attention_mask=True\n",
    "    )\n",
    "    \n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        \n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to -100 (ignored in loss)\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        \n",
    "        labels.append(label_ids)\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Apply tokenization to the datasets\n",
    "tokenized_train = dataset[\"train\"].map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "tokenized_test = dataset[\"test\"].map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"test\"].column_names\n",
    ")\n",
    "\n",
    "print(f\"Keys in tokenized dataset: {list(tokenized_train.features.keys())}\")\n",
    "print(f\"Example input_ids shape: {tokenized_train[0]['input_ids'][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define Metrics and Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the seqeval metric\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "# Define the compute_metrics function\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [id_to_label[str(p)] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id_to_label[str(l)] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Define Training Arguments and Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./layoutlm-ner-results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Initialize the data collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluation_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {evaluation_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save the Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_save_path = \"./layoutlm-ner-finetuned\"\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Test the Model on a Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sample(sample_idx=0, dataset_split=\"test\"):\n",
    "    \"\"\"Test the model on a sample from the dataset.\"\"\"\n",
    "    # Get a sample from the test set\n",
    "    sample = dataset[dataset_split][sample_idx]\n",
    "    \n",
    "    # Tokenize the sample\n",
    "    tokens = tokenizer(\n",
    "        sample[\"words\"],\n",
    "        boxes=sample[\"boxes\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "        is_split_into_words=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Move to the correct device\n",
    "    tokens = {k: v.to(device) for k, v in tokens.items()}\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = torch.argmax(outputs.logits, dim=2)[0].cpu().numpy()\n",
    "    \n",
    "    # Map predictions back to labels\n",
    "    word_ids = tokens.word_ids()[0]\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    \n",
    "    for idx, word_idx in enumerate(word_ids):\n",
    "        if word_idx is not None:\n",
    "            # Only consider the first token of each word\n",
    "            if idx == 0 or word_ids[idx - 1] != word_idx:\n",
    "                predicted_label = id_to_label[str(predictions[idx])]\n",
    "                true_label = id_to_label[str(sample[\"ner_tags\"][word_idx])]\n",
    "                \n",
    "                predicted_labels.append(predicted_label)\n",
    "                true_labels.append(true_label)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Sample words:\", sample[\"words\"])\n",
    "    print(\"\\nPredictions:\")\n",
    "    for word, pred_label, true_label in zip(sample[\"words\"], predicted_labels, true_labels):\n",
    "        if pred_label != true_label:\n",
    "            print(f\"{word:20} | Predicted: {pred_label:20} | True: {true_label:20} | INCORRECT\")\n",
    "        else:\n",
    "            print(f\"{word:20} | Predicted: {pred_label:20} | True: {true_label:20}\")\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct = sum(p == t for p, t in zip(predicted_labels, true_labels))\n",
    "    total = len(predicted_labels)\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    \n",
    "    print(f\"\\nAccuracy: {accuracy:.2f} ({correct}/{total})\")\n",
    "\n",
    "# Try predicting a sample\n",
    "predict_sample(sample_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. (Optional) Make Predictions on New Documents\n",
    "\n",
    "This section demonstrates how to use the fine-tuned model on new documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_new_document(words, boxes):\n",
    "    \"\"\"Make predictions on a new document.\"\"\"\n",
    "    # Ensure boxes are normalized to 0-1000\n",
    "    normalized_boxes = [[min(max(0, coord), 1000) for coord in box] for box in boxes]\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = tokenizer(\n",
    "        words,\n",
    "        boxes=normalized_boxes,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "        is_split_into_words=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Move to the correct device\n",
    "    tokens = {k: v.to(device) for k, v in tokens.items()}\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = torch.argmax(outputs.logits, dim=2)[0].cpu().numpy()\n",
    "    \n",
    "    # Map predictions back to labels\n",
    "    word_ids = tokens.word_ids()[0]\n",
    "    results = []\n",
    "    \n",
    "    for idx, word_idx in enumerate(word_ids):\n",
    "        if word_idx is not None:\n",
    "            # Only consider the first token of each word\n",
    "            if idx == 0 or word_ids[idx - 1] != word_idx:\n",
    "                predicted_label = id_to_label[str(predictions[idx])]\n",
    "                results.append({\n",
    "                    \"word\": words[word_idx],\n",
    "                    \"box\": boxes[word_idx],\n",
    "                    \"label\": predicted_label\n",
    "                })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage (uncommment to use):\n",
    "# new_words = [\"This\", \"is\", \"a\", \"sample\", \"document\"]\n",
    "# new_boxes = [[100, 100, 150, 120], [160, 100, 180, 120], [190, 100, 210, 120], \n",
    "#              [220, 100, 300, 120], [310, 100, 400, 120]]\n",
    "# results = predict_on_new_document(new_words, new_boxes)\n",
    "# for item in results:\n",
    "#     print(f\"{item['word']:20} | {item['label']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
